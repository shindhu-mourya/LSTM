{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "LSTM - Assignment_14.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z6YqsjVEpLuP",
        "colab_type": "text"
      },
      "source": [
        "## Assignment : 14"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mlr6RDAvpLuR",
        "colab_type": "text"
      },
      "source": [
        "<pre>\n",
        "1. Download the preprocessed DonorsChoose data from here <a href='https://drive.google.com/file/d/1GU3LIJJ3zS1xLXXe-sdItSJHtI5txjVO/view?usp=sharing'>Dataset</a>\n",
        "2. Split the data into train, cv, and test\n",
        "3. After step 2 you have to train 3 types of models as discussed below. \n",
        "4. For all the model use <a href='https://scikit-learn.org/stable/modules/model_evaluation.html#roc-metrics'>'auc'</a> as a metric. check <a href='https://datascience.stackexchange.com/a/20192'>this</a> for using auc as a metric. you need to print the AUC value for each epoch. Note: you should NOT use the tf.metric.auc\n",
        "5. You are free to choose any number of layers/hiddden units but you have to use same type of architectures shown below. \n",
        "6. You can use any one of the optimizers and choice of Learning rate and momentum, resources: <a href='http://cs231n.github.io/neural-networks-3/'>cs231n class notes</a>, <a href='https://www.youtube.com/watch?v=hd_KFJ5ktUc'>cs231n class video</a>. \n",
        "7. You should Save the best model weights.\n",
        "8. For all the model's use <a href='https://www.youtube.com/watch?v=2U6Jl7oqRkM'>TensorBoard</a> and plot the Metric value and Loss with epoch. While submitting, take a screenshot of plots and include those images in .ipynb notebook and PDF. \n",
        "9. Use Categorical Cross Entropy as Loss to minimize.\n",
        "10. try to get AUC more than 0.8 for atleast one model\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v82E_vgqpLuT",
        "colab_type": "text"
      },
      "source": [
        "### Model-1\n",
        "\n",
        "Build and Train deep neural network as shown below"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PjHcnRbdpLuU",
        "colab_type": "text"
      },
      "source": [
        "<img src='https://i.imgur.com/w395Yk9.png'>\n",
        "ref: https://i.imgur.com/w395Yk9.png"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTZn5KFDpLuV",
        "colab_type": "text"
      },
      "source": [
        "- __Input_seq_total_text_data__ --- You have to give Total text data columns. After this use the Embedding layer to get word vectors. Use given predefined glove word vectors, don't train any word vectors. After this use LSTM and get the LSTM output and Flatten that output. \n",
        "- __Input_school_state__ --- Give 'school_state' column as input to embedding layer and Train the Keras Embedding layer. \n",
        "- __Project_grade_category__  --- Give 'project_grade_category' column as input to embedding layer and Train the Keras Embedding layer.\n",
        "- __Input_clean_categories__ --- Give 'input_clean_categories' column as input to embedding layer and Train the Keras Embedding layer.\n",
        "- __Input_clean_subcategories__ --- Give 'input_clean_subcategories' column as input to embedding layer and Train the Keras Embedding layer.\n",
        "- __Input_clean_subcategories__ --- Give 'input_teacher_prefix' column as input to embedding layer and Train the Keras Embedding layer.\n",
        "- __Input_remaining_teacher_number_of_previously_posted_projects._resource_summary_contains_numerical_digits._price._quantity__ ---concatenate remaining columns and add a Dense layer after that. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GA1GBtGipLuW",
        "colab_type": "text"
      },
      "source": [
        "- For LSTM, you can choose your sequence padding methods on your own or you can train your LSTM without padding, there is no restriction on that."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DmrD7eqkpLuY",
        "colab_type": "text"
      },
      "source": [
        "Below is an example of embedding layer for a categorical columns. In below code all are dummy values, we gave only for referance. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_zmGSulpLuZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://stats.stackexchange.com/questions/270546/how-does-keras-embedding-layer-work\n",
        "input_layer = Input(shape=(n,))\n",
        "embedding = Embedding(no_1, no_2, input_length=n)(input_layer)\n",
        "flatten = Flatten()(embedding)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ah8-2l8DpLud",
        "colab_type": "text"
      },
      "source": [
        "### 1. Go through this blog, if you have any doubt on using predefined Embedding values in Embedding layer - https://machinelearningmastery.com/use-word-embedding-layers-deep-learning-keras/\n",
        "### 2. Please go through this link https://keras.io/getting-started/functional-api-guide/ and check the 'Multi-input and multi-output models' then you will get to know how to give multiple inputs. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OEuwPI44pLud",
        "colab_type": "text"
      },
      "source": [
        "### Model-2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JhuD2Q-EpLue",
        "colab_type": "text"
      },
      "source": [
        "Use the same model as above but for 'input_seq_total_text_data' give only some words in the sentance not all the words. Filter the words as below. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXN03iAYpLuf",
        "colab_type": "text"
      },
      "source": [
        "<pre>\n",
        "1. Train the TF-IDF on the Train data feature 'essay' <br>\n",
        "2. Get the idf value for each word we have in the train data. <br>\n",
        "3. Remove the low idf value and high idf value words from our data. Do some analysis on the Idf values and based on those values choose the low and high threshold value. Because very frequent words and very very rare words don't give much information. (you can plot a box plots and take only the idf scores within IQR range and corresponding words)<br>\n",
        "4. Train the LSTM after removing the Low and High idf value words. (In model-1 Train on total data but in Model-2 train on data after removing some words based on IDF values)\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "awePXG7VpLuf",
        "colab_type": "text"
      },
      "source": [
        "### Model-3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCs8ve7rpLug",
        "colab_type": "text"
      },
      "source": [
        "<img src='https://i.imgur.com/fkQ8nGo.png'>\n",
        "ref: https://i.imgur.com/fkQ8nGo.png"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebt6tPYwpLuh",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "- __input_seq_total_text_data__: <br>\n",
        "<pre>\n",
        "    . Use text column('essay'), and use the Embedding layer to get word vectors. <br>\n",
        "    . Use given predefined glove word vectors, don't train any word vectors. <br>\n",
        "    . Use LSTM that is given above, get the LSTM output and Flatten that output. <br>\n",
        "    . You are free to preprocess the input text as you needed. <br>\n",
        "</pre>\n",
        "- __Other_than_text_data__:<br>\n",
        "<pre>\n",
        "    . Convert all your Categorical values to onehot coded and then concatenate all these onehot vectors <br>\n",
        "    . Neumerical values and use <a href='https://keras.io/getting-started/sequential-model-guide/#sequence-classification-with-1d-convolutions'>CNN1D</a> as shown in above figure. <br>\n",
        "    . You are free to choose all CNN parameters like kernel sizes, stride.<br>\n",
        "    \n",
        "</pre>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iwpqt1M1TGTZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from numpy import asarray\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from numpy import array\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing import sequence\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Flatten,LSTM\n",
        "from keras.layers import Dense,Input\n",
        "from keras.layers.embeddings import Embedding\n",
        "from sklearn.preprocessing import Normalizer\n",
        "from keras.layers import concatenate,Dropout,BatchNormalization\n",
        "from keras.models import Model\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from tensorboardcolab import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNB6JOzMeN9e",
        "colab_type": "code",
        "outputId": "6aa6e14b-716f-4f75-9ae1-57cd3145b194",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "drive.mount('/content/gdrive')\n",
        "\n",
        "project_data = pd.read_csv(\"./gdrive/My Drive/Colab Notebooks/preprocessed_data.csv\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jNKMr_BQffqn",
        "colab_type": "code",
        "outputId": "a870947c-46d3-46c3-c8e6-5a13e3cd3017",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        }
      },
      "source": [
        "project_data.head()"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>school_state</th>\n",
              "      <th>teacher_prefix</th>\n",
              "      <th>project_grade_category</th>\n",
              "      <th>teacher_number_of_previously_posted_projects</th>\n",
              "      <th>project_is_approved</th>\n",
              "      <th>clean_categories</th>\n",
              "      <th>clean_subcategories</th>\n",
              "      <th>essay</th>\n",
              "      <th>price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ca</td>\n",
              "      <td>mrs</td>\n",
              "      <td>grades_prek_2</td>\n",
              "      <td>53</td>\n",
              "      <td>1</td>\n",
              "      <td>math_science</td>\n",
              "      <td>appliedsciences health_lifescience</td>\n",
              "      <td>i fortunate enough use fairy tale stem kits cl...</td>\n",
              "      <td>725.05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ut</td>\n",
              "      <td>ms</td>\n",
              "      <td>grades_3_5</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>specialneeds</td>\n",
              "      <td>specialneeds</td>\n",
              "      <td>imagine 8 9 years old you third grade classroo...</td>\n",
              "      <td>213.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ca</td>\n",
              "      <td>mrs</td>\n",
              "      <td>grades_prek_2</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>literacy_language</td>\n",
              "      <td>literacy</td>\n",
              "      <td>having class 24 students comes diverse learner...</td>\n",
              "      <td>329.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ga</td>\n",
              "      <td>mrs</td>\n",
              "      <td>grades_prek_2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>appliedlearning</td>\n",
              "      <td>earlydevelopment</td>\n",
              "      <td>i recently read article giving students choice...</td>\n",
              "      <td>481.04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>wa</td>\n",
              "      <td>mrs</td>\n",
              "      <td>grades_3_5</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>literacy_language</td>\n",
              "      <td>literacy</td>\n",
              "      <td>my students crave challenge eat obstacles brea...</td>\n",
              "      <td>17.74</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  school_state  ...   price\n",
              "0           ca  ...  725.05\n",
              "1           ut  ...  213.03\n",
              "2           ca  ...  329.00\n",
              "3           ga  ...  481.04\n",
              "4           wa  ...   17.74\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "f95ut-Fq39Xb"
      },
      "source": [
        "<h3>converting each categorical features to numeric</h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "31fbf104-132a-468f-9cf3-06b3d2c9adc2",
        "id": "wKPoJgDu39Xo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Converting categorical project grade to numeric\n",
        "grade_dict = {}\n",
        "k = 0\n",
        "for s in project_data['project_grade_category'].values:\n",
        "  rank = grade_dict.get(s,-1)\n",
        "  if(rank == -1):\n",
        "    grade_dict[s] = k\n",
        "    k += 1\n",
        "print(\"Total number of unique grade. {}\".format(len(grade_dict.keys())))\n",
        "\n",
        "def grade_numeric(x):\n",
        "  return grade_dict[x]\n",
        "\n",
        "grade_feat = project_data['project_grade_category'].map(grade_numeric)\n",
        "project_data['numeric_project_grade_category'] = grade_feat"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of unique grade. 4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "85d6bbcc-e8c3-42df-b8b2-11a257863939",
        "id": "DuTwh1AG39X1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Converting categorical clean_categories to numerical features.\n",
        "sub_dict = {}\n",
        "k = 0\n",
        "for s in project_data['clean_categories'].values:\n",
        "  is_present = sub_dict.get(s,-1)\n",
        "  if(is_present == -1):\n",
        "    sub_dict[s] = k\n",
        "    k += 1\n",
        "print(\"Total number of unique subject category. {}\".format(len(sub_dict.keys())))\n",
        "\n",
        "def subject_numeric(x):\n",
        "  return sub_dict[x]\n",
        "\n",
        "sub_feat = project_data['clean_categories'].map(subject_numeric)\n",
        "project_data['numeric_clean_categories'] = sub_feat"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of unique subject category. 51\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GruzngXy39X9",
        "outputId": "e0ccce27-d78b-4b18-84b2-70e5a07d191c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Converting clean sub_categories to numerical features.\n",
        "ssub_dict = {}\n",
        "k = 0\n",
        "for s in project_data['clean_subcategories'].values:\n",
        "  is_present = ssub_dict.get(s,-1)\n",
        "  if(is_present == -1):\n",
        "    ssub_dict[s] = k\n",
        "    k += 1\n",
        "print(\"Total number of unique subject subcategory. {}\".format(len(ssub_dict.keys())))\n",
        "\n",
        "def ssub_numeric(x):\n",
        "  return ssub_dict[x]\n",
        "\n",
        "subject_sub_feat = project_data['clean_subcategories'].map(ssub_numeric)\n",
        "project_data['numeric_clean_subcategories'] = subject_sub_feat"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of unique subject subcategory. 401\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dm0zkg_A39YJ",
        "outputId": "bd30e7b2-a6bc-4187-c36c-5a08ac1d8655",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Converting categorical teacher prefix to numerical\n",
        "teacher_dict = {}\n",
        "k = 0\n",
        "for s in project_data['teacher_prefix'].values:\n",
        "  is_present = teacher_dict.get(s,-1)\n",
        "  if(is_present == -1):\n",
        "    teacher_dict[s] = k\n",
        "    k += 1\n",
        "print(\"Total number of unique teacher prefix. {}\".format(len(teacher_dict.keys())))\n",
        "\n",
        "def teacher_numeric(x):\n",
        "  return teacher_dict[x]\n",
        "  \n",
        "teacher_feat = project_data['teacher_prefix'].map(teacher_numeric)\n",
        "project_data['numeric_teacher_prefix'] = teacher_feat\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of unique teacher prefix. 5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4kBRwZ0N39YV",
        "outputId": "c89c2632-a75c-4087-dbb8-2ec9233ad535",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Converting categorical features of school to numerical features.\n",
        "ss_dict = {} # This will store  school state with their numerical value\n",
        "school_state = project_data['school_state'].values\n",
        "k = 0\n",
        "for s in school_state:\n",
        "  is_present = ss_dict.get(s,-1)\n",
        "  if(is_present == -1):\n",
        "    ss_dict[s] = k\n",
        "    k += 1\n",
        "print(\"Total number of unique school states. {}\".format(len(ss_dict.keys())))\n",
        "def ss_numerical(x):\n",
        "  return ss_dict[x]\n",
        "\n",
        "state_feat = project_data['school_state'].map(ss_numerical)\n",
        "project_data['numeric_school_state'] = state_feat"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of unique school states. 51\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wA8S5w8Q39Yd"
      },
      "source": [
        "<h3> split project_data into train, cv and test datasets</h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vS-F_G8AKpV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = project_data['project_is_approved'].values\n",
        "project_data.drop(['project_is_approved'], axis=1, inplace=True)\n",
        "X=project_data\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, stratify=y)\n",
        "X_train, X_cv, y_train, y_cv = train_test_split(X_train, y_train, test_size=0.20, stratify=y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "udFQVzvjzzHM",
        "colab": {}
      },
      "source": [
        "# For project_grade_category\n",
        "grade_train = X_train['numeric_project_grade_category'].values.reshape(-1,1)\n",
        "grade_test = X_test['numeric_project_grade_category'].values.reshape(-1,1)\n",
        "grade_cv = X_cv['numeric_project_grade_category'].values.reshape(-1,1)\n",
        "\n",
        "# For clean_categories\n",
        "cat_train = X_train['numeric_clean_categories'].values.reshape(-1,1)\n",
        "cat_test = X_test['numeric_clean_categories'].values.reshape(-1,1)\n",
        "cat_cv = X_cv['numeric_clean_categories'].values.reshape(-1,1)\n",
        "\n",
        "# For clean_subcategories\n",
        "sub_cat_train = X_train['numeric_clean_subcategories'].values.reshape(-1,1)\n",
        "sub_cat_test = X_test['numeric_clean_subcategories'].values.reshape(-1,1)\n",
        "sub_cat_cv = X_cv['numeric_clean_subcategories'].values.reshape(-1,1)\n",
        "\n",
        "# for teacher_prefix\n",
        "teacher_train = X_train['numeric_teacher_prefix'].values.reshape(-1,1)\n",
        "teacher_test = X_test['numeric_teacher_prefix'].values.reshape(-1,1)\n",
        "teacher_cv = X_cv['numeric_teacher_prefix'].values.reshape(-1,1)\n",
        "\n",
        "# For school state\n",
        "state_train = X_train['numeric_school_state'].values.reshape(-1,1)\n",
        "state_test = X_test['numeric_school_state'].values.reshape(-1,1)\n",
        "state_cv = X_cv['numeric_school_state'].values.reshape(-1,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4W5lbvhTHImq",
        "colab_type": "text"
      },
      "source": [
        "<h3>preprocessing essay</h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uMGjVZJqlCNe",
        "colab": {}
      },
      "source": [
        "# https://stackoverflow.com/a/47091490/4084039\n",
        "import re\n",
        "\n",
        "def decontracted(phrase):\n",
        "    # specific\n",
        "    phrase = re.sub(r\"won't\", \"will not\", phrase)\n",
        "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
        "\n",
        "    # general\n",
        "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
        "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
        "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
        "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
        "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
        "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
        "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
        "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
        "    return phrase"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FrXT9L9IlCPm",
        "colab": {}
      },
      "source": [
        "# https://gist.github.com/sebleier/554280\n",
        "# we are removing the words from the stop words list: 'no', 'nor', 'not'\n",
        "stopwords= ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\",\\\n",
        "            \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', \\\n",
        "            'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their',\\\n",
        "            'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', \\\n",
        "            'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', \\\n",
        "            'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', \\\n",
        "            'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after',\\\n",
        "            'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further',\\\n",
        "            'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more',\\\n",
        "            'most', 'other', 'some', 'such', 'only', 'own', 'same', 'so', 'than', 'too', 'very', \\\n",
        "            's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', \\\n",
        "            've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn',\\\n",
        "            \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn',\\\n",
        "            \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", \\\n",
        "            'won', \"won't\", 'wouldn', \"wouldn't\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8OZvluxQHFRy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Combining all the above stundents \n",
        "def preprocess_text(text_data):\n",
        "    preprocessed_text = []\n",
        "    # tqdm is for printing the status bar\n",
        "    for sentance in tqdm(text_data):\n",
        "        sent = decontracted(sentance)\n",
        "        sent = sent.replace('\\\\r', ' ')\n",
        "        sent = sent.replace('\\\\n', ' ')\n",
        "        sent = sent.replace('\\\\\"', ' ')\n",
        "        sent = re.sub('[^A-Za-z]+', ' ', sent)\n",
        "        # https://gist.github.com/sebleier/554280\n",
        "        sent = ' '.join(e for e in sent.split() if e.lower() not in stopwords)\n",
        "        preprocessed_text.append(sent.lower().strip())\n",
        "    return preprocessed_text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLswJJ-4VqRO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "14629a4f-a513-4e79-8b98-79dd9c5559a2"
      },
      "source": [
        "# for essay data\n",
        "essay_train = preprocess_text(X_train['essay'].values)\n",
        "essay_test = preprocess_text(X_test['essay'].values)\n",
        "essay_cv = preprocess_text(X_cv['essay'].values)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 69918/69918 [00:26<00:00, 2665.60it/s]\n",
            "100%|██████████| 21850/21850 [00:08<00:00, 2663.66it/s]\n",
            "100%|██████████| 17480/17480 [00:06<00:00, 2639.99it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PyVu4PP54srd",
        "colab_type": "text"
      },
      "source": [
        "<h3>converting each word in essay text to numeric</h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jmFOH4A64oZz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "b34255fd-bf8f-4b7e-b038-6e1e0455a02f"
      },
      "source": [
        "# integer encode sequences of words\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(essay_train)\n",
        "X_train_seq = tokenizer.texts_to_sequences(essay_train)\n",
        "# vocabulary size\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "max_len = 600\n",
        "# padding the vectors of each datapoint to fixed length of 600.\n",
        "X_train_tokens = pad_sequences(X_train_seq,maxlen = max_len,padding='post')\n",
        "\n",
        "# integer encode sequences of words\n",
        "X_cv_seq = tokenizer.texts_to_sequences(essay_cv)\n",
        "max_len = 600\n",
        "# padding the vectors of each datapoint to fixed length of 600.\n",
        "X_cv_tokens = pad_sequences(X_cv_seq,maxlen = max_len,padding='post')\n",
        "\n",
        "# integer encode sequences of words\n",
        "X_test_seq = tokenizer.texts_to_sequences(essay_test)\n",
        "max_len = 600\n",
        "# padding the vectors of each datapoint to fixed length of 600.\n",
        "X_test_tokens = pad_sequences(X_test_seq,maxlen = max_len,padding='post')\n",
        "\n",
        "print(X_train_tokens.shape)\n",
        "print(X_cv_tokens.shape)\n",
        "print(X_test_tokens.shape)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(69918, 600)\n",
            "(17480, 600)\n",
            "(21850, 600)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ws7bUT-eVhoF",
        "colab_type": "code",
        "outputId": "67622d75-5c7c-411f-9061-5771d76fb1ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#f = open(\"./gdrive/My Drive/glove_vectors\",'rb')\n",
        "\n",
        "# we will load the whole glove vectors .\n",
        "embeddings_index = {}\n",
        "f = open(\"./gdrive/My Drive/glove.42B.300d.txt\",'r',encoding=\"utf-8\")\n",
        "for line in f:\n",
        "\tvalues = line.split()\n",
        "\tword = values[0]\n",
        "\tcoefs = asarray(values[1:], dtype='float32')\n",
        "\tembeddings_index[word] = coefs\n",
        "f.close()\n",
        "print('Loaded %s word vectors.' % len(embeddings_index))\n",
        "\n",
        "# Credit : https://machinelearningmastery.com/use-word-embedding-layers-deep-learning-keras/\n",
        "embedding_matrix = np.zeros((vocab_size, 300))\n",
        "for word, i in tokenizer.word_index.items():\n",
        "\tembedding_vector = embeddings_index.get(word)\n",
        "\tif embedding_vector is not None:\n",
        "\t\tembedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded 1917495 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VluoLaaF4_Ey",
        "colab_type": "text"
      },
      "source": [
        "<h3> Input layer, embedding layer, LSTM and flattening for encoded essay text</h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ecOHiHb4-Bc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "276ccc34-8063-4981-c3da-8aad1bde62c5"
      },
      "source": [
        "# For essay data\n",
        "input_layer1 = Input(shape=(600,))\n",
        "embedding = Embedding(vocab_size, 300, input_length=max_len, weights=[embedding_matrix], trainable=False)(input_layer1)\n",
        "\n",
        "lstm_out1 = LSTM(64,return_sequences=True)(embedding)\n",
        "lstm_out2 = LSTM(128,return_sequences=True)(lstm_out1)\n",
        "lstm_out = Flatten()(lstm_out2)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SV2fW_tV5L6f",
        "colab_type": "text"
      },
      "source": [
        "<h3> embedding layer and flattening for each encode categorical features</h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KYlM5wRR5k_D",
        "colab": {}
      },
      "source": [
        "# For project_grade_category\n",
        "from keras.layers import Flatten\n",
        "input_layer2 = Input(shape=(1,))\n",
        "e1 = Embedding(4,32,input_length=1)(input_layer2)#no. of unique grade category is 4\n",
        "flatten1 = Flatten()(e1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9NT-oCq-5k_a",
        "colab": {}
      },
      "source": [
        "# For clean_categories\n",
        "input_layer3 = Input(shape=(1,))\n",
        "e2 = Embedding(51,32,input_length=1)(input_layer3)#no. of unique clean categories is 51\n",
        "flatten2 = Flatten()(e2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "D0yiFDyU5k_m",
        "colab": {}
      },
      "source": [
        "# For clean_subcategories\n",
        "input_layer4 = Input(shape=(1,))\n",
        "e3 = Embedding(401,32,input_length=1)(input_layer4)#no. of unique clean subcategories is 401\n",
        "flatten3 = Flatten()(e3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZkfC3ZZj5k_2",
        "colab": {}
      },
      "source": [
        "# For teacher_prefix\n",
        "input_layer5 = Input(shape=(1,))\n",
        "e4 = Embedding(5,32,input_length=1)(input_layer5)#no. of unique teacher prefix is 5\n",
        "flatten4 = Flatten()(e4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hjKjvMcr5lAK",
        "colab": {}
      },
      "source": [
        "# for school state\n",
        "input_layer6 = Input(shape=(1,))\n",
        "e5 = Embedding(51,32,input_length=1)(input_layer6)#no. of unique school state is 51\n",
        "flatten5 = Flatten()(e5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d25Et_kJU4LV",
        "colab_type": "text"
      },
      "source": [
        "<h3>Normalizing the numerical features: price</h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kXChfR7gUTtL",
        "colab_type": "code",
        "outputId": "8ba863a2-e938-405b-ddc0-d374dc12167b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "normalizer = Normalizer()\n",
        "normalizer.fit(X_train['price'].values.reshape(-1,1))\n",
        "\n",
        "X_train_price_norm = normalizer.transform(X_train['price'].values.reshape(-1,1))\n",
        "X_cv_price_norm = normalizer.transform(X_cv['price'].values.reshape(-1,1))\n",
        "X_test_price_norm = normalizer.transform(X_test['price'].values.reshape(-1,1))\n",
        "\n",
        "print(\"After vectorizations\")\n",
        "print(X_train_price_norm.shape, y_train.shape)\n",
        "print(X_cv_price_norm.shape, y_cv.shape)\n",
        "print(X_test_price_norm.shape, y_test.shape)\n",
        "print(\"=\"*100)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "After vectorizations\n",
            "(69918, 1) (69918,)\n",
            "(17480, 1) (17480,)\n",
            "(21850, 1) (21850,)\n",
            "====================================================================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywhs048FVQuP",
        "colab_type": "text"
      },
      "source": [
        "<h3>Normalizing the numerical features: teacher_number_of_previously_projects</h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VhaVcyc1UI35",
        "colab_type": "code",
        "outputId": "8c654965-3c4c-4c50-e81a-10cc296b37fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "normalizer.fit(X_train['teacher_number_of_previously_posted_projects'].values.reshape(-1,1))\n",
        "\n",
        "X_train_tnppp_norm = normalizer.transform(X_train['teacher_number_of_previously_posted_projects'].values.reshape(-1,1))\n",
        "X_cv_tnppp_norm = normalizer.transform(X_cv['teacher_number_of_previously_posted_projects'].values.reshape(-1,1))\n",
        "X_test_tnppp_norm = normalizer.transform(X_test['teacher_number_of_previously_posted_projects'].values.reshape(-1,1))\n",
        "\n",
        "print(\"After vectorizations\")\n",
        "print(X_train_tnppp_norm.shape, y_train.shape)\n",
        "print(X_cv_tnppp_norm.shape, y_cv.shape)\n",
        "print(X_test_tnppp_norm.shape, y_test.shape)\n",
        "print(\"=\"*100)\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "After vectorizations\n",
            "(69918, 1) (69918,)\n",
            "(17480, 1) (17480,)\n",
            "(21850, 1) (21850,)\n",
            "====================================================================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KvI5iP7C5tKl",
        "colab_type": "text"
      },
      "source": [
        "<h3>concating all the numerical features using hstack</h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brk3zSiRM3ok",
        "colab_type": "code",
        "outputId": "93b97189-9d51-4375-f4ee-2534f1807a51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "X_train_rem = np.hstack((X_train_price_norm, X_train_tnppp_norm))\n",
        "X_cv_rem = np.hstack((X_cv_price_norm, X_cv_tnppp_norm))\n",
        "X_test_rem = np.hstack((X_test_price_norm, X_test_tnppp_norm))\n",
        "\n",
        "print(\"Final Data matrix\")\n",
        "print(X_train_rem.shape, y_train.shape)\n",
        "print(X_cv_rem.shape, y_cv.shape)\n",
        "print(X_test_rem.shape, y_test.shape)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Final Data matrix\n",
            "(69918, 2) (69918,)\n",
            "(17480, 2) (17480,)\n",
            "(21850, 2) (21850,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vEmDz6YY55XA",
        "colab_type": "text"
      },
      "source": [
        "<h3>Input layer and Dense hidden layer for above concated numerical features</h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uMhV7t_OMl5e",
        "colab": {}
      },
      "source": [
        "# For cocatenated features\n",
        "input_layer7 = Input(shape=(2,))\n",
        "rem_feat_dense = Dense(64, activation='relu')(input_layer7)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YjBqVr8dmILm"
      },
      "source": [
        "# Model 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-B3gUZ2rf6KU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "f0a7774a-1fcb-4d7f-c65c-d21a891c6306"
      },
      "source": [
        "# credict : https://keras.io/getting-started/functional-api-guide/\n",
        "# Trying out the first architecture\n",
        "\n",
        "x = concatenate([lstm_out,flatten1,flatten2,flatten3,flatten4,flatten5,rem_feat_dense])\n",
        "\n",
        "# We stack a deep densely-connected network on top\n",
        "x = Dense(256, activation='relu')(x)\n",
        "x = Dropout(0.25)(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "x = Dropout(0.25)(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dense(64,activation='relu')(x)\n",
        "\n",
        "main_output = Dense(2, activation='softmax')(x)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eL2doSfxZnov",
        "colab": {}
      },
      "source": [
        "model = Model(inputs=[input_layer1,input_layer2,input_layer3,input_layer4,input_layer5,input_layer6,input_layer7], outputs=[main_output])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AIjpafsjrkq_",
        "colab": {}
      },
      "source": [
        "# Credict: https://stackoverflow.com/questions/41032551/how-to-compute-receiving-operating-characteristic-roc-and-auc-in-keras\n",
        "\n",
        "def aucroc(y_true, y_pred):\n",
        "    # Getting the actual y in a list\n",
        "    actual_y = tf.map_fn(lambda x: x[0] ,y_true)\n",
        "    # Using sklearn \"roc_auc_score\" to get roc_auc.\n",
        "    return tf.py_func(roc_auc_score, (actual_y, y_pred[:,1]), tf.double)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "B26ov4dIITx-",
        "outputId": "3b4eceb5-2ef1-4b2a-af86-c7fffdfff3aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "from tensorboardcolab import *\n",
        "tbc = TensorBoardColab()"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wait for 8 seconds...\n",
            "TensorBoard link:\n",
            "http://c50720c5.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NkFUihKWYnff",
        "outputId": "0c9bbf23-4e16-4c8c-dbf8-081d6dd3c5ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy',metrics=[aucroc],loss_weights=[1.])\n",
        "\n",
        "model.fit([X_train_tokens,grade_train,cat_train,sub_cat_train,teacher_train,state_train,X_train_rem], [y_train], epochs=8, batch_size=512,\n",
        "           callbacks=[TensorBoardColabCallback(tbc)], validation_data=([X_cv_tokens,grade_cv,cat_cv,sub_cat_cv,teacher_cv,state_cv,X_cv_rem], [y_cv]))"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 69918 samples, validate on 17480 samples\n",
            "Epoch 1/8\n",
            "69918/69918 [==============================] - 1268s 18ms/step - loss: 0.4253 - aucroc: 0.6355 - val_loss: 0.3836 - val_aucroc: 0.7245\n",
            "Epoch 2/8\n",
            "69918/69918 [==============================] - 1233s 18ms/step - loss: 0.3843 - aucroc: 0.7170 - val_loss: 0.3765 - val_aucroc: 0.7384\n",
            "Epoch 3/8\n",
            "69918/69918 [==============================] - 1216s 17ms/step - loss: 0.3756 - aucroc: 0.7359 - val_loss: 0.3775 - val_aucroc: 0.7278\n",
            "Epoch 4/8\n",
            "69918/69918 [==============================] - 1220s 17ms/step - loss: 0.3698 - aucroc: 0.7468 - val_loss: 0.3711 - val_aucroc: 0.7450\n",
            "Epoch 5/8\n",
            "69918/69918 [==============================] - 1222s 17ms/step - loss: 0.3638 - aucroc: 0.7572 - val_loss: 0.3655 - val_aucroc: 0.7536\n",
            "Epoch 6/8\n",
            "69918/69918 [==============================] - 1218s 17ms/step - loss: 0.3581 - aucroc: 0.7685 - val_loss: 0.3703 - val_aucroc: 0.7496\n",
            "Epoch 7/8\n",
            "69918/69918 [==============================] - 1220s 17ms/step - loss: 0.3515 - aucroc: 0.7796 - val_loss: 0.3697 - val_aucroc: 0.7501\n",
            "Epoch 8/8\n",
            "69918/69918 [==============================] - 1237s 18ms/step - loss: 0.3433 - aucroc: 0.7917 - val_loss: 0.3791 - val_aucroc: 0.7522\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f478bc1ef28>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tpA7BcsTqQFt",
        "outputId": "b673eae5-2d4d-4026-c908-fd6d0ea659ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "score = model.evaluate([X_test_tokens,grade_test,cat_test,sub_cat_test,teacher_test,state_test,X_test_rem],\n",
        "                       [y_test],batch_size=512)\n",
        "print('Test score:', score[0]) \n",
        "print('Test AUC :', score[1])"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "21850/21850 [==============================] - 99s 5ms/step\n",
            "Test score: 0.3811307204315264\n",
            "Test AUC : 0.7496628754318015\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AAbl_6wiNT2v"
      },
      "source": [
        "# Model 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bipIS9yQTM8s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We will use tfidf to vectorize eaasy data and will remove those words which have very high or very low idf values.\n",
        "# We will fit the vectorizer on train data and will use it on cv and test dataset.\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "vectorizer = TfidfVectorizer(use_idf=True)\n",
        "vectorizer.fit_transform(X_train['essay'].values)\n",
        "# This returnsthe idf value of all the words.\n",
        "idf_value = vectorizer.idf_\n",
        "# This returns the name of all the words\n",
        "all_words = vectorizer.get_feature_names()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUgCAvnfevBa",
        "colab_type": "code",
        "outputId": "ed703979-d29c-44c7-beb9-27d6bdaa297f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "# Plotting box plot of idf values.\n",
        "sorted_idf = np.sort(idf_value)#to sort idf value\n",
        "x = [i for i in range(len(idf_value))]\n",
        "plt.plot(x,sorted_idf,label='idf')\n",
        "plt.xlabel(\"Index of words\")\n",
        "plt.ylabel(\"Idf value\")\n",
        "plt.title(\"Boxplot of idf values\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEZEcp0QgIpLj/j+IHOpN3mEulAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uI_Tpub_gsjO",
        "colab_type": "code",
        "outputId": "8254f1cd-3532-40ad-8f03-e8db35b75c1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "word_dict = {}\n",
        "for i in range(len(idf_value)):\n",
        "  if idf_value[i]>=4 and idf_value[i]<=10:\n",
        "    word_dict[all_words[i]] = idf_value[i]\n",
        "                                   \n",
        "print(len(word_dict))                                   "
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "14891\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oC5S3nelh4Sy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "2e967f9c-b19b-479d-d080-2c3670b30638"
      },
      "source": [
        "#for train datapoints\n",
        "new_train_text = []\n",
        "for sentence in tqdm(essay_train):\n",
        "  new_sentence = \" \"\n",
        "  for word in sentence.split():\n",
        "    word_found = word_dict.get(word,-1)\n",
        "    if word_found>0:\n",
        "      new_sentence+=word+\" \"\n",
        "  \n",
        "  new_train_text.append(new_sentence)\n",
        "  \n",
        "#for cv datapoints\n",
        "new_cv_text = []\n",
        "for sentence in tqdm(essay_cv):\n",
        "  new_sentence = \" \"\n",
        "  for word in sentence.split():\n",
        "    word_found = word_dict.get(word,-1)\n",
        "    if word_found>0:\n",
        "      new_sentence+=word+\" \"\n",
        "  \n",
        "  new_cv_text.append(new_sentence)\n",
        "  \n",
        "#for text datapoints\n",
        "new_test_text = []\n",
        "for sentence in tqdm(essay_test):\n",
        "  new_sentence = \" \"\n",
        "  for word in sentence.split():\n",
        "    word_found = word_dict.get(word,-1)\n",
        "    if word_found>0:\n",
        "      new_sentence+=word+\" \"\n",
        "  \n",
        "  new_test_text.append(new_sentence)  "
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 69918/69918 [00:04<00:00, 14269.88it/s]\n",
            "100%|██████████| 17480/17480 [00:01<00:00, 14033.99it/s]\n",
            "100%|██████████| 21850/21850 [00:01<00:00, 13742.11it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZO_30JxkG4l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "4a12238a-4a6c-43db-d9b8-db8bd2beab92"
      },
      "source": [
        "# integer encode sequences of words\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(new_train_text)\n",
        "X_train_seq = tokenizer.texts_to_sequences(new_train_text)\n",
        "# vocabulary size\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "max_len = 400\n",
        "# padding the vectors of each datapoint to fixed length of 600.\n",
        "X_train_tokens_cnn = pad_sequences(X_train_seq,maxlen = max_len,padding='post')\n",
        "\n",
        "# integer encode sequences of words\n",
        "X_cv_seq = tokenizer.texts_to_sequences(new_cv_text)\n",
        "# padding the vectors of each datapoint to fixed length of 600.\n",
        "X_cv_tokens_cnn = pad_sequences(X_cv_seq,maxlen = max_len,padding='post')\n",
        "\n",
        "# integer encode sequences of words\n",
        "X_test_seq = tokenizer.texts_to_sequences(new_test_text)\n",
        "# padding the vectors of each datapoint to fixed length of 600.\n",
        "X_test_tokens_cnn = pad_sequences(X_test_seq,maxlen = max_len,padding='post')\n",
        "\n",
        "print(X_train_tokens_cnn.shape)\n",
        "print(X_cv_tokens_cnn.shape)\n",
        "print(X_test_tokens_cnn.shape)"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(69918, 400)\n",
            "(17480, 400)\n",
            "(21850, 400)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "scrX7EMUFXyy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Credit : https://machinelearningmastery.com/use-word-embedding-layers-deep-learning-keras/\n",
        "embedding_matrix = np.zeros((vocab_size, 300))\n",
        "for word, i in tokenizer.word_index.items():\n",
        "\tembedding_vector = embeddings_index.get(word)\n",
        "\tif embedding_vector is not None:\n",
        "\t\tembedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wL3F60XllSKO"
      },
      "source": [
        "<h3> Input layer, embedding layer, LSTM and flattening for encoded essay text</h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GuiISyVwlSKP",
        "colab": {}
      },
      "source": [
        "# For essay data\n",
        "input_layer_new = Input(shape=(400,))\n",
        "embedding = Embedding(vocab_size, 300, input_length=max_len, weights=[embedding_matrix], trainable=False)(input_layer_new)\n",
        "\n",
        "lstm_out1 = LSTM(64,return_sequences=True)(embedding)\n",
        "lstm_out2 = LSTM(128,return_sequences=True)(lstm_out1)\n",
        "lstm_out_new = Flatten()(lstm_out2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KyBLYMy_lj11",
        "colab": {}
      },
      "source": [
        "# credict : https://keras.io/getting-started/functional-api-guide/\n",
        "# Trying out the first architecture\n",
        "\n",
        "x = concatenate([lstm_out_new,flatten1,flatten2,flatten3,flatten4,flatten5,rem_feat_dense])\n",
        "\n",
        "# We stack a deep densely-connected network on top\n",
        "x = Dense(128, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dense(64, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dense(32,activation='relu')(x)\n",
        "\n",
        "main_output = Dense(2, activation='softmax')(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sjgTjoyFlj15",
        "colab": {}
      },
      "source": [
        "model = Model(inputs=[input_layer_new,input_layer2,input_layer3,input_layer4,input_layer5,input_layer6,input_layer7], outputs=[main_output])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "dfda9845-104e-49b8-b6a4-ff375cb45e9c",
        "id": "uPtu4rZ8lj2E",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "tbc = TensorBoardColab()"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wait for 8 seconds...\n",
            "TensorBoard link:\n",
            "http://c50720c5.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "c321e056-1f9d-429c-a294-18f9dd1df87e",
        "id": "TZbi3Y8klj2I",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy',metrics=[aucroc],loss_weights=[1.])\n",
        "\n",
        "model.fit([X_train_tokens_cnn,grade_train,cat_train,sub_cat_train,teacher_train,state_train,X_train_rem], [y_train], epochs=6, batch_size=512,\n",
        "           callbacks=[TensorBoardColabCallback(tbc)], validation_data=([X_cv_tokens_cnn,grade_cv,cat_cv,sub_cat_cv,teacher_cv,state_cv,X_cv_rem], [y_cv]))"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 69918 samples, validate on 17480 samples\n",
            "Epoch 1/6\n",
            "69918/69918 [==============================] - 767s 11ms/step - loss: 0.4702 - aucroc: 0.5727 - val_loss: 0.4036 - val_aucroc: 0.6789\n",
            "Epoch 2/6\n",
            "69918/69918 [==============================] - 760s 11ms/step - loss: 0.4080 - aucroc: 0.6627 - val_loss: 0.3969 - val_aucroc: 0.6991\n",
            "Epoch 3/6\n",
            "69918/69918 [==============================] - 765s 11ms/step - loss: 0.4007 - aucroc: 0.6807 - val_loss: 0.3960 - val_aucroc: 0.7018\n",
            "Epoch 4/6\n",
            "69918/69918 [==============================] - 777s 11ms/step - loss: 0.3957 - aucroc: 0.6946 - val_loss: 0.3949 - val_aucroc: 0.7129\n",
            "Epoch 5/6\n",
            "69918/69918 [==============================] - 767s 11ms/step - loss: 0.3896 - aucroc: 0.7075 - val_loss: 0.4437 - val_aucroc: 0.7135\n",
            "Epoch 6/6\n",
            "69918/69918 [==============================] - 774s 11ms/step - loss: 0.3865 - aucroc: 0.7131 - val_loss: 0.3846 - val_aucroc: 0.7172\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f476ebc79e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "fbd0ddbc-ac7f-45df-e907-8646d669f48e",
        "id": "8Smur1Talj2L",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "score = model.evaluate([X_test_tokens_cnn,grade_test,cat_test,sub_cat_test,teacher_test,state_test,X_test_rem],\n",
        "                       [y_test],batch_size=512)\n",
        "print('Test score:', score[0]) \n",
        "print('Test AUC :', score[1])"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "21850/21850 [==============================] - 64s 3ms/step\n",
            "Test score: 0.3863066413500762\n",
            "Test AUC : 0.7152759812228051\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lZKwJHp7lnbo",
        "colab_type": "text"
      },
      "source": [
        "<h2>Model-3</h2>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVGURrYGmfLJ",
        "colab_type": "text"
      },
      "source": [
        "<h3>Normalizing the numerical features: Price</h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qd6NHG16mfLK",
        "colab_type": "code",
        "outputId": "bb585952-ef22-4ba9-f1ed-06a28488613e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "normalizer = Normalizer()\n",
        "normalizer.fit(X_train['price'].values.reshape(-1,1))\n",
        "\n",
        "X_train_price_norm = normalizer.transform(X_train['price'].values.reshape(-1,1))\n",
        "X_cv_price_norm = normalizer.transform(X_cv['price'].values.reshape(-1,1))\n",
        "X_test_price_norm = normalizer.transform(X_test['price'].values.reshape(-1,1))\n",
        "\n",
        "print(\"After vectorizations\")\n",
        "print(X_train_price_norm.shape, y_train.shape)\n",
        "print(X_cv_price_norm.shape, y_cv.shape)\n",
        "print(X_test_price_norm.shape, y_test.shape)\n",
        "print(\"=\"*100)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "After vectorizations\n",
            "(69918, 1) (69918,)\n",
            "(17480, 1) (17480,)\n",
            "(21850, 1) (21850,)\n",
            "====================================================================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8JohcpWZmfLN",
        "colab_type": "text"
      },
      "source": [
        "<h3>Normalizing the numerical features: teacher_number_of_previously_posted_projects</h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blfKl86imfLO",
        "colab_type": "code",
        "outputId": "59d59be5-a688-4c97-9314-5dd89cc54b7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "normalizer.fit(X_train['teacher_number_of_previously_posted_projects'].values.reshape(-1,1))\n",
        "\n",
        "X_train_tnppp_norm = normalizer.transform(X_train['teacher_number_of_previously_posted_projects'].values.reshape(-1,1))\n",
        "X_cv_tnppp_norm = normalizer.transform(X_cv['teacher_number_of_previously_posted_projects'].values.reshape(-1,1))\n",
        "X_test_tnppp_norm = normalizer.transform(X_test['teacher_number_of_previously_posted_projects'].values.reshape(-1,1))\n",
        "\n",
        "print(\"After vectorizations\")\n",
        "print(X_train_tnppp_norm.shape, y_train.shape)\n",
        "print(X_cv_tnppp_norm.shape, y_cv.shape)\n",
        "print(X_test_tnppp_norm.shape, y_test.shape)\n",
        "print(\"=\"*100)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "After vectorizations\n",
            "(69918, 1) (69918,)\n",
            "(17480, 1) (17480,)\n",
            "(21850, 1) (21850,)\n",
            "====================================================================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EoCrnyoZmfLb",
        "colab_type": "text"
      },
      "source": [
        "<h3>one hot encoding the catogorical features:clean_categories</h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mGmHbRbmfLc",
        "colab_type": "code",
        "outputId": "f0ef7fcd-84b4-4f63-9af5-9b2b128a5975",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "vectorizer = CountVectorizer()\n",
        "vectorizer.fit(X_train['clean_categories'].values)\n",
        "\n",
        "X_train_categories_ohe = vectorizer.transform(X_train['clean_categories'].values)\n",
        "X_cv_categories_ohe = vectorizer.transform(X_cv['clean_categories'].values)\n",
        "X_test_categories_ohe = vectorizer.transform(X_test['clean_categories'].values)\n",
        "\n",
        "print(\"After vectorizations\")\n",
        "print(X_train_categories_ohe.shape, y_train.shape)\n",
        "print(X_cv_categories_ohe.shape, y_cv.shape)\n",
        "print(X_test_categories_ohe.shape, y_test.shape)\n",
        "print(vectorizer.get_feature_names())\n",
        "print(\"=\"*100)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "After vectorizations\n",
            "(69918, 9) (69918,)\n",
            "(17480, 9) (17480,)\n",
            "(21850, 9) (21850,)\n",
            "['appliedlearning', 'care_hunger', 'health_sports', 'history_civics', 'literacy_language', 'math_science', 'music_arts', 'specialneeds', 'warmth']\n",
            "====================================================================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T73R2xkumfLd",
        "colab_type": "text"
      },
      "source": [
        "<h3>one hot encoding the catogorical features: clean_subcategories</h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_kfhSGumfLe",
        "colab_type": "code",
        "outputId": "5c60ded7-b988-497b-bcb3-f38d209fac99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "vectorizer = CountVectorizer()\n",
        "vectorizer.fit(X_train['clean_subcategories'].values)\n",
        "X_train_sub_categories_ohe = vectorizer.transform(X_train['clean_subcategories'].values)\n",
        "X_cv_sub_categories_ohe = vectorizer.transform(X_cv['clean_subcategories'].values)\n",
        "X_test_sub_categories_ohe = vectorizer.transform(X_test['clean_subcategories'].values)\n",
        "\n",
        "print(\"After vectorizations\")\n",
        "print(X_train_sub_categories_ohe.shape, y_train.shape)\n",
        "print(X_cv_sub_categories_ohe.shape, y_cv.shape)\n",
        "print(X_test_sub_categories_ohe.shape, y_test.shape)\n",
        "print(vectorizer.get_feature_names())\n",
        "print(\"=\"*100)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "After vectorizations\n",
            "(69918, 30) (69918,)\n",
            "(17480, 30) (17480,)\n",
            "(21850, 30) (21850,)\n",
            "['appliedsciences', 'care_hunger', 'charactereducation', 'civics_government', 'college_careerprep', 'communityservice', 'earlydevelopment', 'economics', 'environmentalscience', 'esl', 'extracurricular', 'financialliteracy', 'foreignlanguages', 'gym_fitness', 'health_lifescience', 'health_wellness', 'history_geography', 'literacy', 'literature_writing', 'mathematics', 'music', 'nutritioneducation', 'other', 'parentinvolvement', 'performingarts', 'socialsciences', 'specialneeds', 'teamsports', 'visualarts', 'warmth']\n",
            "====================================================================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ceV3E4DkmfLf",
        "colab_type": "text"
      },
      "source": [
        "<h3>one hot encoding the catogorical features: school_state</h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lrmfma8xmfLg",
        "colab_type": "code",
        "outputId": "4ac2396b-cc18-4d33-babc-b2da8d937026",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "vectorizer = CountVectorizer()\n",
        "vectorizer.fit(X_train['school_state'].values) # fit has to happen only on train data\n",
        "\n",
        "# we use the fitted CountVectorizer to convert the text to vector\n",
        "X_train_state_ohe = vectorizer.transform(X_train['school_state'].values)\n",
        "X_cv_state_ohe = vectorizer.transform(X_cv['school_state'].values)\n",
        "X_test_state_ohe = vectorizer.transform(X_test['school_state'].values)\n",
        "\n",
        "print(\"After vectorizations\")\n",
        "print(X_train_state_ohe.shape, y_train.shape)\n",
        "print(X_cv_state_ohe.shape, y_cv.shape)\n",
        "print(X_test_state_ohe.shape, y_test.shape)\n",
        "print(vectorizer.get_feature_names())\n",
        "print(\"=\"*100)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "After vectorizations\n",
            "(69918, 51) (69918,)\n",
            "(17480, 51) (17480,)\n",
            "(21850, 51) (21850,)\n",
            "['ak', 'al', 'ar', 'az', 'ca', 'co', 'ct', 'dc', 'de', 'fl', 'ga', 'hi', 'ia', 'id', 'il', 'in', 'ks', 'ky', 'la', 'ma', 'md', 'me', 'mi', 'mn', 'mo', 'ms', 'mt', 'nc', 'nd', 'ne', 'nh', 'nj', 'nm', 'nv', 'ny', 'oh', 'ok', 'or', 'pa', 'ri', 'sc', 'sd', 'tn', 'tx', 'ut', 'va', 'vt', 'wa', 'wi', 'wv', 'wy']\n",
            "====================================================================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IgqXuFalmfLh",
        "colab_type": "text"
      },
      "source": [
        "<h3>one hot encoding the catogorical features: teacher_prefix</h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-mmUaoECmfLi",
        "colab_type": "code",
        "outputId": "4634f476-51b2-46cc-aed2-8bd1f445178f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "vectorizer.fit(X_train['teacher_prefix'].values) # fit has to happen only on train data\n",
        "\n",
        "# we use the fitted CountVectorizer to convert the text to vector\n",
        "X_train_teacher_ohe = vectorizer.transform(X_train['teacher_prefix'].values)\n",
        "X_cv_teacher_ohe = vectorizer.transform(X_cv['teacher_prefix'].values)\n",
        "X_test_teacher_ohe = vectorizer.transform(X_test['teacher_prefix'].values)\n",
        "\n",
        "print(\"After vectorizations\")\n",
        "print(X_train_teacher_ohe.shape, y_train.shape)\n",
        "print(X_cv_teacher_ohe.shape, y_cv.shape)\n",
        "print(X_test_teacher_ohe.shape, y_test.shape)\n",
        "print(vectorizer.get_feature_names())\n",
        "print(\"=\"*100)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "After vectorizations\n",
            "(69918, 5) (69918,)\n",
            "(17480, 5) (17480,)\n",
            "(21850, 5) (21850,)\n",
            "['dr', 'mr', 'mrs', 'ms', 'teacher']\n",
            "====================================================================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WAeQ7jEhmfLk",
        "colab_type": "text"
      },
      "source": [
        "<h3>one hot encoding the catogorical features: project_grade_category</h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pj3F5CWamfLl",
        "colab_type": "code",
        "outputId": "7f7e2896-5a50-446c-a1a0-69ba9ba3f7f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# we use count vectorizer to convert the values into one hot encoded features\n",
        "vectorizer = CountVectorizer()\n",
        "vectorizer.fit(X_train['project_grade_category'].values)\n",
        "print(vectorizer.get_feature_names())\n",
        "\n",
        "\n",
        "X_train_grade_ohe = vectorizer.transform(X_train['project_grade_category'].values)\n",
        "print(X_train_grade_ohe.shape, y_train.shape)\n",
        "\n",
        "X_cv_grade_ohe = vectorizer.transform(X_cv['project_grade_category'].values)\n",
        "print(X_cv_grade_ohe.shape, y_cv.shape)\n",
        "\n",
        "X_test_grade_ohe = vectorizer.transform(X_test['project_grade_category'].values)\n",
        "print(X_test_grade_ohe.shape, y_test.shape)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['grades_3_5', 'grades_6_8', 'grades_9_12', 'grades_prek_2']\n",
            "(69918, 4) (69918,)\n",
            "(17480, 4) (17480,)\n",
            "(21850, 4) (21850,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tE_HVeoLqUw8",
        "colab_type": "text"
      },
      "source": [
        "<h3>Concatinating all the categorical and numerical features</h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOgWlYZJp2kt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "e7afabaa-398d-48c7-f163-8567b89c1515"
      },
      "source": [
        "from scipy.sparse import hstack,csr_matrix\n",
        "X_tr_cat = hstack((X_train_categories_ohe, X_train_sub_categories_ohe, X_train_teacher_ohe, X_train_state_ohe, X_train_grade_ohe, X_train_price_norm, X_train_tnppp_norm))\n",
        "               \n",
        "X_cv_cat = hstack((X_cv_categories_ohe, X_cv_sub_categories_ohe, X_cv_teacher_ohe, X_cv_state_ohe, X_cv_grade_ohe, X_cv_price_norm, X_cv_tnppp_norm))\n",
        "\n",
        "X_te_cat = hstack((X_test_categories_ohe, X_test_sub_categories_ohe, X_test_teacher_ohe, X_test_state_ohe, X_test_grade_ohe, X_test_price_norm, X_test_tnppp_norm))\n",
        "\n",
        "print(\"Final Data matrix\")\n",
        "print(X_tr_cat.shape, y_train.shape)\n",
        "print(X_cv_cat.shape, y_cv.shape)\n",
        "print(X_te_cat.shape, y_test.shape)\n",
        "print(\"=\"*100)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Final Data matrix\n",
            "(69918, 101) (69918,)\n",
            "(17480, 101) (17480,)\n",
            "(21850, 101) (21850,)\n",
            "====================================================================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "asvDEcbsVw2A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "bf0a8fd6-0877-41d9-e5bd-684d021ee406"
      },
      "source": [
        "import numpy as np\n",
        "X_tr_cat1 = X_tr_cat.toarray()\n",
        "X_tr_cat  = np.reshape(X_tr_cat1,X_tr_cat1.shape + (1,))\n",
        "\n",
        "X_cv_cat1 = X_cv_cat.toarray()\n",
        "X_cv_cat  = np.reshape(X_cv_cat1,X_cv_cat1.shape + (1,))\n",
        "\n",
        "X_te_cat1 = X_te_cat.toarray()\n",
        "X_te_cat = np.reshape(X_te_cat1,X_te_cat1.shape + (1,))\n",
        "\n",
        "print(X_tr_cat.shape)\n",
        "print(X_cv_cat.shape)\n",
        "print(X_te_cat.shape)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(69918, 101, 1)\n",
            "(17480, 101, 1)\n",
            "(21850, 101, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TiMlXiLErMGY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.layers import Conv1D\n",
        "input_layer_cnn = Input(shape=(101,1))\n",
        "conv1 = Conv1D(32, 3, activation='relu')(input_layer_cnn)\n",
        "\n",
        "conv2 = Conv1D(54, 3, activation='relu')(conv1)\n",
        "\n",
        "conv3 = Conv1D(84, 3, activation='relu')(conv2)\n",
        "\n",
        "conv4 = Conv1D(112, 3, activation='relu')(conv3)\n",
        "\n",
        "flatten_con = Flatten()(conv4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nKpVxXjLw0Aj",
        "colab": {}
      },
      "source": [
        "# credict : https://keras.io/getting-started/functional-api-guide/\n",
        "# Trying out the first architecture\n",
        "\n",
        "x = concatenate([lstm_out,flatten_con])\n",
        "\n",
        "# We stack a deep densely-connected network on top\n",
        "x = Dense(256, activation='relu')(x)\n",
        "x = Dropout(0.25)(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "x = Dropout(0.25)(x)\n",
        "x = Dense(64,activation='relu')(x)\n",
        "\n",
        "main_output = Dense(2, activation='softmax')(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Kfb1KXkgw0Ar",
        "colab": {}
      },
      "source": [
        "model = Model(inputs=[input_layer1,input_layer_cnn], outputs=[main_output])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "e7a8fd56-cd7f-4cc9-b1f7-e096f4304f7b",
        "id": "2xu9doYmw0A4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "tbc = TensorBoardColab()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wait for 8 seconds...\n",
            "TensorBoard link:\n",
            "https://790eb149.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "00c90983-053a-4b31-b25b-acf3176bde82",
        "id": "BzTaCZnNw0A-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        }
      },
      "source": [
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy',metrics=[aucroc],loss_weights=[1.])\n",
        "\n",
        "model.fit([X_train_tokens,X_tr_cat], [y_train], epochs=4, batch_size=512, callbacks=[TensorBoardColabCallback(tbc)], \n",
        "          validation_data=([X_cv_tokens,X_cv_cat], [y_cv]))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From <ipython-input-29-51c9c3811ab9>:6: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "tf.py_func is deprecated in TF V2. Instead, there are two\n",
            "    options available in V2.\n",
            "    - tf.py_function takes a python function which manipulates tf eager\n",
            "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
            "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
            "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
            "    being differentiable using a gradient tape.\n",
            "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
            "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
            "    stateful argument making all functions stateful.\n",
            "    \n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Train on 69918 samples, validate on 17480 samples\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorboardcolab/core.py:49: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks.py:1122: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
            "\n",
            "Epoch 1/4\n",
            "69918/69918 [==============================] - 1183s 17ms/step - loss: 0.4059 - aucroc: 0.6732 - val_loss: 0.3955 - val_aucroc: 0.7254\n",
            "Epoch 2/4\n",
            "69918/69918 [==============================] - 1177s 17ms/step - loss: 0.3792 - aucroc: 0.7378 - val_loss: 0.3773 - val_aucroc: 0.7304\n",
            "Epoch 3/4\n",
            "69918/69918 [==============================] - 1173s 17ms/step - loss: 0.3674 - aucroc: 0.7596 - val_loss: 0.3814 - val_aucroc: 0.7332\n",
            "Epoch 4/4\n",
            "69918/69918 [==============================] - 1162s 17ms/step - loss: 0.3546 - aucroc: 0.7814 - val_loss: 0.3771 - val_aucroc: 0.7416\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f148afe6ac8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "39f65a70-6a87-4e5c-bf42-978cf89a415e",
        "id": "m1-ENCopw0BB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "score = model.evaluate([X_test_tokens,X_te_cat], [y_test], batch_size=512)\n",
        "print('Test score:', score[0]) \n",
        "print('Test AUC :', score[1])"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "21850/21850 [==============================] - 100s 5ms/step\n",
            "Test score: 0.3788366698700449\n",
            "Test AUC : 0.7396574669128284\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DxTRdL1wG1RF"
      },
      "source": [
        "# Conclusion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cjdg7aQiGzkg",
        "outputId": "bd45e41d-1cb5-4e66-accb-7ad4c365e6fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "from prettytable import PrettyTable\n",
        "\n",
        "x = PrettyTable(['Model','Train AUC','Validation AUC','Test AUC'])\n",
        "x.add_row(['Model1','0.7917','0.7522','0.7496'])\n",
        "x.add_row(['Model2','0.8028','0.7221','0.7107'])\n",
        "x.add_row(['Model3','0.7131','0.7172','0.7152'])\n",
        "print(x)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------+-----------+----------------+----------+\n",
            "| Model  | Train AUC | Validation AUC | Test AUC |\n",
            "+--------+-----------+----------------+----------+\n",
            "| Model1 |   0.7917  |     0.7522     |  0.7496  |\n",
            "| Model2 |   0.8028  |     0.7221     |  0.7107  |\n",
            "| Model3 |   0.7131  |     0.7172     |  0.7152  |\n",
            "+--------+-----------+----------------+----------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-YsNrEr7Dlw",
        "colab_type": "text"
      },
      "source": [
        "<h3>1.In model-1 and model-2 i have used activation function \"sigmoid\" while for model-3 i have used activation function \"relu\"</h3>\n",
        "<h3>2.In model-1 i have used all words in whole data corpus and tokenize to numeric integer using keras tokenizer and for model-2 i have taken words based on tf-idf , selected words which moderate tf-idf values and for text in data corpus makes new sentances with those words which have moderate tf-idf values(not too high and not too less).</h3>\n",
        "<h3>3.In model-3 for all features in data corpus except text features applied one hot enncoding to encode each features and concatenated all the features using hstack.Applied convolutional layer(1D) on top of it.</h3>\n",
        "<h3>4.for getting aucroc value with each epoch i have tensonboard callback</h3>\n",
        "<h3>5.I enjoyed lot while doing this assignment.LSTM is indeed one of best algorithm in whole deep learning.</h3>\n",
        "  "
      ]
    }
  ]
}